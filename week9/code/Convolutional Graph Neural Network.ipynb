{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
      "Collecting torch-scatter==latest+cpu\n",
      "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.4.0/torch_scatter-latest%2Bcpu-cp37-cp37m-macosx_10_9_x86_64.whl (525kB)\n",
      "\u001b[K     |████████████████████████████████| 532kB 1.7MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.4.0.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
      "Collecting torch-sparse==latest+cpu\n",
      "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.4.0/torch_sparse-latest%2Bcpu-cp37-cp37m-macosx_10_9_x86_64.whl (721kB)\n",
      "\u001b[K     |████████████████████████████████| 727kB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-sparse==latest+cpu) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from scipy->torch-sparse==latest+cpu) (1.16.4)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-sparse==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.4.0.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
      "Collecting torch-cluster==latest+cpu\n",
      "  Downloading https://pytorch-geometric.com/whl/torch-1.4.0/torch_cluster-latest%2Bcpu-cp37-cp37m-macosx_10_9_x86_64.whl (466 kB)\n",
      "\u001b[K     |████████████████████████████████| 466 kB 370 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-cluster==latest+cpu) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from scipy->torch-cluster==latest+cpu) (1.18.1)\n",
      "Installing collected packages: torch-cluster\n",
      "Successfully installed torch-cluster-1.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-cluster==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.4.0.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0.html\n",
      "Collecting torch-spline-conv==latest+cpu\n",
      "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.4.0/torch_spline_conv-latest%2Bcpu-cp37-cp37m-macosx_10_9_x86_64.whl (187kB)\n",
      "\u001b[K     |████████████████████████████████| 194kB 266kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
      "Successfully installed torch-spline-conv-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-spline-conv==latest+cpu -f https://pytorch-geometric.com/whl/torch-1.4.0.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (1.4.3)\n",
      "Requirement already satisfied: numpy in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (1.18.1)\n",
      "Requirement already satisfied: numba in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (0.49.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (0.21.2)\n",
      "Collecting networkx\n",
      "  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (1.0.3)\n",
      "Requirement already satisfied: plyfile in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (0.7.2)\n",
      "Requirement already satisfied: scipy in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (1.3.0)\n",
      "Requirement already satisfied: rdflib in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (5.0.0)\n",
      "Requirement already satisfied: googledrivedownloader in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (0.4)\n",
      "Requirement already satisfied: requests in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (2.22.0)\n",
      "Requirement already satisfied: torch in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (1.4.0)\n",
      "Requirement already satisfied: h5py in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (2.9.0)\n",
      "Requirement already satisfied: scikit-image in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from torch-geometric) (0.15.0)\n",
      "Requirement already satisfied: llvmlite<=0.33.0.dev0,>=0.31.0.dev0 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from numba->torch-geometric) (0.32.0)\n",
      "Requirement already satisfied: setuptools in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from numba->torch-geometric) (46.1.3.post20200330)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from scikit-learn->torch-geometric) (0.13.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from networkx->torch-geometric) (4.4.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from pandas->torch-geometric) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from pandas->torch-geometric) (2.8.1)\n",
      "Requirement already satisfied: isodate in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from rdflib->torch-geometric) (0.6.0)\n",
      "Collecting pyparsing\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from rdflib->torch-geometric) (1.14.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from requests->torch-geometric) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from requests->torch-geometric) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from requests->torch-geometric) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from requests->torch-geometric) (1.24.3)\n",
      "Collecting matplotlib!=3.0.0,>=2.0.0\n",
      "  Downloading matplotlib-3.2.1-cp37-cp37m-macosx_10_9_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=4.3.0 in /Users/chupi/anaconda3/envs/pytorch/lib/python3.7/site-packages (from scikit-image->torch-geometric) (7.1.2)\n",
      "Collecting PyWavelets>=0.4.0\n",
      "  Downloading PyWavelets-1.1.1-cp37-cp37m-macosx_10_9_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio>=2.0.1\n",
      "  Downloading imageio-2.8.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.2.0-cp37-cp37m-macosx_10_9_x86_64.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Installing collected packages: networkx, pyparsing, kiwisolver, cycler, matplotlib, PyWavelets, imageio\n",
      "Successfully installed PyWavelets-1.1.1 cycler-0.10.0 imageio-2.8.0 kiwisolver-1.2.0 matplotlib-3.2.1 networkx-2.4 pyparsing-2.4.7\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodes in graph\n",
    "x = torch.tensor([[2,1], [5,6], [3,7], [12,0]], dtype=torch.float)  #each node has two attributes\n",
    "y = torch.tensor([0, 1, 0, 1], dtype=torch.float)                   #label of each node\n",
    "\n",
    "#edges - graph connectivity\n",
    "# in COO format\n",
    "# first list: index of source node; second list: index of target nodes\n",
    "# order is not important\n",
    "edge_index = torch.tensor([[0, 1, 2, 0, 3],\n",
    "                           [1, 0, 1, 3, 2]], dtype=torch.long)\n",
    "\n",
    "#data\n",
    "data = Data(x=x, y=y, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 5], x=[4, 2], y=[4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## display the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = to_networkx(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = data.y[list(graph.nodes)].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_networkx(graph, node_color=node_labels, cmap=plt.get_cmap('Set1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a benchmark dataset -> Node classification\n",
    "\n",
    "Example data: CoRA dataset\n",
    "\n",
    "The Cora dataset consists of Machine Learning papers. These papers are classified into one of the following seven classes:\n",
    "\n",
    "\t\t- Case_Based\n",
    "\t\t- Genetic_Algorithms\n",
    "\t\t- Neural_Networks\n",
    "\t\t- Probabilistic_Methods\n",
    "\t\t- Reinforcement_Learning\n",
    "\t\t- Rule_Learning\n",
    "\t\t- Theory\n",
    "\n",
    "The papers were selected in a way such that in the final corpus every paper cites or is cited by atleast one other paper. There are 2708 papers in the whole corpus. \n",
    "\n",
    "After stemming and removing stopwords we were left with a vocabulary of size 1433 unique words. All words with document frequency less than 10 were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)  # a single, undirected citation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1433"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_node_features # number of features for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask.sum().item() #training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.val_mask.sum().item() #val data number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.test_mask.sum().item() #test data number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN model\n",
    "\n",
    "http://tkipf.github.io/graph-convolutional-networks/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_model_summary(model):\n",
    "    \n",
    "    model_params_list = list(model.named_parameters())\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    line_new = \"{:>20}  {:>25} {:>15}\".format(\"Layer.Parameter\", \"Param Tensor Shape\", \"Param #\")\n",
    "    print(line_new)\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    for elem in model_params_list:\n",
    "        p_name = elem[0] \n",
    "        p_shape = list(elem[1].size())\n",
    "        p_count = torch.tensor(elem[1].size()).prod().item()\n",
    "        line_new = \"{:>20}  {:>25} {:>15}\".format(p_name, str(p_shape), str(p_count))\n",
    "        print(line_new)\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    total_params = sum([param.nelement() for param in model.parameters()])\n",
    "    print(\"Total params:\", total_params)\n",
    "    num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"Trainable params:\", num_trainable_params)\n",
    "    print(\"Non-trainable params:\", total_params - num_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "     Layer.Parameter         Param Tensor Shape         Param #\n",
      "----------------------------------------------------------------\n",
      "        conv1.weight                 [1433, 16]           22928\n",
      "          conv1.bias                       [16]              16\n",
      "        conv2.weight                    [16, 7]             112\n",
      "          conv2.bias                        [7]               7\n",
      "----------------------------------------------------------------\n",
      "Total params: 23063\n",
      "Trainable params: 23063\n",
      "Non-trainable params: 0\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "gnn_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 1.9495536088943481\n",
      "Epoch 20 loss: 0.2586601674556732\n",
      "Epoch 40 loss: 0.05975053831934929\n",
      "Epoch 60 loss: 0.05132346972823143\n",
      "Epoch 80 loss: 0.04427019879221916\n",
      "Epoch 100 loss: 0.04855520650744438\n",
      "Epoch 120 loss: 0.02983223646879196\n",
      "Epoch 140 loss: 0.03208761662244797\n",
      "Epoch 160 loss: 0.0388658232986927\n",
      "Epoch 180 loss: 0.03348282352089882\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    if epoch%20 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss}')\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7880\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph classification model\n",
    "\n",
    "all graph classification datasets from http://graphkernels.cs.tu-dortmund.de/ and their cleaned versions, the QM7 and QM9 dataset, and a handful of 3D mesh/point cloud datasets like FAUST, ModelNet10/40 and ShapeNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GraphConv, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset('/tmp/PROTEINS', name='PROTEINS')\n",
    "dataset = dataset.shuffle()\n",
    "n = len(dataset) // 10\n",
    "test_dataset = dataset[:n]\n",
    "train_dataset = dataset[n:]\n",
    "test_loader = DataLoader(test_dataset, batch_size=60)\n",
    "train_loader = DataLoader(train_dataset, batch_size=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = GraphConv(dataset.num_features, 128)\n",
    "        self.pool1 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv2 = GraphConv(128, 128)\n",
    "        self.pool2 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv3 = GraphConv(128, 128)\n",
    "        self.pool3 = TopKPooling(128, ratio=0.8)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(256, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 64)\n",
    "        self.lin3 = torch.nn.Linear(64, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.log_softmax(self.lin3(x), dim=-1)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "     Layer.Parameter         Param Tensor Shape         Param #\n",
      "----------------------------------------------------------------\n",
      "        conv1.weight                   [3, 128]             384\n",
      "    conv1.lin.weight                   [128, 3]             384\n",
      "      conv1.lin.bias                      [128]             128\n",
      "        pool1.weight                   [1, 128]             128\n",
      "        conv2.weight                 [128, 128]           16384\n",
      "    conv2.lin.weight                 [128, 128]           16384\n",
      "      conv2.lin.bias                      [128]             128\n",
      "        pool2.weight                   [1, 128]             128\n",
      "        conv3.weight                 [128, 128]           16384\n",
      "    conv3.lin.weight                 [128, 128]           16384\n",
      "      conv3.lin.bias                      [128]             128\n",
      "        pool3.weight                   [1, 128]             128\n",
      "         lin1.weight                 [128, 256]           32768\n",
      "           lin1.bias                      [128]             128\n",
      "         lin2.weight                  [64, 128]            8192\n",
      "           lin2.bias                       [64]              64\n",
      "         lin3.weight                    [2, 64]             128\n",
      "           lin3.bias                        [2]               2\n",
      "----------------------------------------------------------------\n",
      "Total params: 108354\n",
      "Trainable params: 108354\n",
      "Non-trainable params: 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "gnn_model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.63015, Train Acc: 0.69361, Test Acc: 0.72072\n",
      "Epoch: 002, Loss: 0.58364, Train Acc: 0.72355, Test Acc: 0.74775\n",
      "Epoch: 003, Loss: 0.56786, Train Acc: 0.72655, Test Acc: 0.75676\n",
      "Epoch: 004, Loss: 0.56600, Train Acc: 0.72555, Test Acc: 0.73874\n",
      "Epoch: 005, Loss: 0.56387, Train Acc: 0.73752, Test Acc: 0.77477\n",
      "Epoch: 006, Loss: 0.54130, Train Acc: 0.74651, Test Acc: 0.77477\n",
      "Epoch: 007, Loss: 0.52640, Train Acc: 0.74451, Test Acc: 0.78378\n",
      "Epoch: 008, Loss: 0.53398, Train Acc: 0.75549, Test Acc: 0.76577\n",
      "Epoch: 009, Loss: 0.53325, Train Acc: 0.75349, Test Acc: 0.74775\n",
      "Epoch: 010, Loss: 0.52646, Train Acc: 0.75848, Test Acc: 0.76577\n",
      "Epoch: 011, Loss: 0.52536, Train Acc: 0.75948, Test Acc: 0.75676\n",
      "Epoch: 012, Loss: 0.52458, Train Acc: 0.76447, Test Acc: 0.75676\n",
      "Epoch: 013, Loss: 0.51213, Train Acc: 0.76747, Test Acc: 0.74775\n",
      "Epoch: 014, Loss: 0.51200, Train Acc: 0.77146, Test Acc: 0.72072\n",
      "Epoch: 015, Loss: 0.51064, Train Acc: 0.77246, Test Acc: 0.72973\n",
      "Epoch: 016, Loss: 0.51497, Train Acc: 0.77046, Test Acc: 0.72072\n",
      "Epoch: 017, Loss: 0.49864, Train Acc: 0.77146, Test Acc: 0.71171\n",
      "Epoch: 018, Loss: 0.50341, Train Acc: 0.77745, Test Acc: 0.72072\n",
      "Epoch: 019, Loss: 0.48854, Train Acc: 0.77844, Test Acc: 0.72072\n",
      "Epoch: 020, Loss: 0.48788, Train Acc: 0.77944, Test Acc: 0.73874\n",
      "Epoch: 021, Loss: 0.48069, Train Acc: 0.77944, Test Acc: 0.72072\n",
      "Epoch: 022, Loss: 0.49072, Train Acc: 0.78643, Test Acc: 0.70270\n",
      "Epoch: 023, Loss: 0.47896, Train Acc: 0.79042, Test Acc: 0.72973\n",
      "Epoch: 024, Loss: 0.48363, Train Acc: 0.78743, Test Acc: 0.73874\n",
      "Epoch: 025, Loss: 0.48240, Train Acc: 0.79341, Test Acc: 0.73874\n",
      "Epoch: 026, Loss: 0.47865, Train Acc: 0.79242, Test Acc: 0.75676\n",
      "Epoch: 027, Loss: 0.46192, Train Acc: 0.79242, Test Acc: 0.74775\n",
      "Epoch: 028, Loss: 0.46027, Train Acc: 0.79441, Test Acc: 0.72973\n",
      "Epoch: 029, Loss: 0.46441, Train Acc: 0.79142, Test Acc: 0.72973\n",
      "Epoch: 030, Loss: 0.47661, Train Acc: 0.79142, Test Acc: 0.72072\n",
      "Epoch: 031, Loss: 0.46234, Train Acc: 0.79541, Test Acc: 0.72973\n",
      "Epoch: 032, Loss: 0.45902, Train Acc: 0.79441, Test Acc: 0.76577\n",
      "Epoch: 033, Loss: 0.47081, Train Acc: 0.79341, Test Acc: 0.70270\n",
      "Epoch: 034, Loss: 0.45998, Train Acc: 0.79242, Test Acc: 0.78378\n",
      "Epoch: 035, Loss: 0.45599, Train Acc: 0.80240, Test Acc: 0.74775\n",
      "Epoch: 036, Loss: 0.45918, Train Acc: 0.80539, Test Acc: 0.74775\n",
      "Epoch: 037, Loss: 0.45034, Train Acc: 0.80439, Test Acc: 0.74775\n",
      "Epoch: 038, Loss: 0.46449, Train Acc: 0.80339, Test Acc: 0.77477\n",
      "Epoch: 039, Loss: 0.45655, Train Acc: 0.78643, Test Acc: 0.76577\n",
      "Epoch: 040, Loss: 0.45609, Train Acc: 0.80040, Test Acc: 0.77477\n",
      "Epoch: 041, Loss: 0.45105, Train Acc: 0.80539, Test Acc: 0.78378\n",
      "Epoch: 042, Loss: 0.46248, Train Acc: 0.80539, Test Acc: 0.78378\n",
      "Epoch: 043, Loss: 0.44522, Train Acc: 0.79840, Test Acc: 0.72973\n",
      "Epoch: 044, Loss: 0.44402, Train Acc: 0.81238, Test Acc: 0.79279\n",
      "Epoch: 045, Loss: 0.43091, Train Acc: 0.81637, Test Acc: 0.74775\n",
      "Epoch: 046, Loss: 0.43588, Train Acc: 0.82136, Test Acc: 0.77477\n",
      "Epoch: 047, Loss: 0.42298, Train Acc: 0.81337, Test Acc: 0.74775\n",
      "Epoch: 048, Loss: 0.42501, Train Acc: 0.81537, Test Acc: 0.75676\n",
      "Epoch: 049, Loss: 0.42617, Train Acc: 0.81637, Test Acc: 0.72072\n",
      "Epoch: 050, Loss: 0.42325, Train Acc: 0.81936, Test Acc: 0.74775\n",
      "Epoch: 051, Loss: 0.40650, Train Acc: 0.82834, Test Acc: 0.76577\n",
      "Epoch: 052, Loss: 0.40403, Train Acc: 0.81737, Test Acc: 0.72973\n",
      "Epoch: 053, Loss: 0.41010, Train Acc: 0.83134, Test Acc: 0.75676\n",
      "Epoch: 054, Loss: 0.40642, Train Acc: 0.83134, Test Acc: 0.72072\n",
      "Epoch: 055, Loss: 0.39467, Train Acc: 0.83234, Test Acc: 0.77477\n",
      "Epoch: 056, Loss: 0.39229, Train Acc: 0.83633, Test Acc: 0.74775\n",
      "Epoch: 057, Loss: 0.39364, Train Acc: 0.83533, Test Acc: 0.70270\n",
      "Epoch: 058, Loss: 0.37955, Train Acc: 0.83832, Test Acc: 0.74775\n",
      "Epoch: 059, Loss: 0.38568, Train Acc: 0.85130, Test Acc: 0.71171\n",
      "Epoch: 060, Loss: 0.35955, Train Acc: 0.85429, Test Acc: 0.71171\n",
      "Epoch: 061, Loss: 0.39412, Train Acc: 0.82435, Test Acc: 0.71171\n",
      "Epoch: 062, Loss: 0.45237, Train Acc: 0.80938, Test Acc: 0.72973\n",
      "Epoch: 063, Loss: 0.42019, Train Acc: 0.82335, Test Acc: 0.71171\n",
      "Epoch: 064, Loss: 0.41568, Train Acc: 0.83832, Test Acc: 0.72973\n",
      "Epoch: 065, Loss: 0.39936, Train Acc: 0.83733, Test Acc: 0.72973\n",
      "Epoch: 066, Loss: 0.37575, Train Acc: 0.84531, Test Acc: 0.74775\n",
      "Epoch: 067, Loss: 0.37608, Train Acc: 0.84830, Test Acc: 0.71171\n",
      "Epoch: 068, Loss: 0.37944, Train Acc: 0.84132, Test Acc: 0.71171\n",
      "Epoch: 069, Loss: 0.35163, Train Acc: 0.84731, Test Acc: 0.72072\n",
      "Epoch: 070, Loss: 0.35925, Train Acc: 0.85729, Test Acc: 0.72072\n",
      "Epoch: 071, Loss: 0.33851, Train Acc: 0.85629, Test Acc: 0.70270\n",
      "Epoch: 072, Loss: 0.34639, Train Acc: 0.87026, Test Acc: 0.68468\n",
      "Epoch: 073, Loss: 0.35479, Train Acc: 0.86926, Test Acc: 0.72072\n",
      "Epoch: 074, Loss: 0.34507, Train Acc: 0.85729, Test Acc: 0.72973\n",
      "Epoch: 075, Loss: 0.36474, Train Acc: 0.83234, Test Acc: 0.69369\n",
      "Epoch: 076, Loss: 0.37980, Train Acc: 0.86327, Test Acc: 0.68468\n",
      "Epoch: 077, Loss: 0.34133, Train Acc: 0.86427, Test Acc: 0.70270\n",
      "Epoch: 078, Loss: 0.33797, Train Acc: 0.86128, Test Acc: 0.69369\n",
      "Epoch: 079, Loss: 0.35447, Train Acc: 0.85928, Test Acc: 0.71171\n",
      "Epoch: 080, Loss: 0.34545, Train Acc: 0.86627, Test Acc: 0.68468\n",
      "Epoch: 081, Loss: 0.33052, Train Acc: 0.85828, Test Acc: 0.71171\n",
      "Epoch: 082, Loss: 0.37784, Train Acc: 0.82036, Test Acc: 0.68468\n",
      "Epoch: 083, Loss: 0.35679, Train Acc: 0.85329, Test Acc: 0.68468\n",
      "Epoch: 084, Loss: 0.33413, Train Acc: 0.86028, Test Acc: 0.72973\n",
      "Epoch: 085, Loss: 0.32790, Train Acc: 0.87126, Test Acc: 0.69369\n",
      "Epoch: 086, Loss: 0.30755, Train Acc: 0.87026, Test Acc: 0.70270\n",
      "Epoch: 087, Loss: 0.33192, Train Acc: 0.86627, Test Acc: 0.68468\n",
      "Epoch: 088, Loss: 0.31503, Train Acc: 0.87824, Test Acc: 0.70270\n",
      "Epoch: 089, Loss: 0.30645, Train Acc: 0.87425, Test Acc: 0.70270\n",
      "Epoch: 090, Loss: 0.32094, Train Acc: 0.87525, Test Acc: 0.69369\n",
      "Epoch: 091, Loss: 0.32130, Train Acc: 0.87725, Test Acc: 0.71171\n",
      "Epoch: 092, Loss: 0.28505, Train Acc: 0.89521, Test Acc: 0.72973\n",
      "Epoch: 093, Loss: 0.30437, Train Acc: 0.89122, Test Acc: 0.71171\n",
      "Epoch: 094, Loss: 0.32712, Train Acc: 0.86427, Test Acc: 0.72072\n",
      "Epoch: 095, Loss: 0.33146, Train Acc: 0.89421, Test Acc: 0.69369\n",
      "Epoch: 096, Loss: 0.31251, Train Acc: 0.88623, Test Acc: 0.70270\n",
      "Epoch: 097, Loss: 0.30083, Train Acc: 0.90220, Test Acc: 0.74775\n",
      "Epoch: 098, Loss: 0.27775, Train Acc: 0.90519, Test Acc: 0.73874\n",
      "Epoch: 099, Loss: 0.28780, Train Acc: 0.89321, Test Acc: 0.72072\n",
      "Epoch: 100, Loss: 0.30223, Train Acc: 0.88922, Test Acc: 0.70270\n",
      "Epoch: 101, Loss: 0.27900, Train Acc: 0.89521, Test Acc: 0.72973\n",
      "Epoch: 102, Loss: 0.32986, Train Acc: 0.87924, Test Acc: 0.70270\n",
      "Epoch: 103, Loss: 0.31002, Train Acc: 0.89022, Test Acc: 0.72973\n",
      "Epoch: 104, Loss: 0.31206, Train Acc: 0.89222, Test Acc: 0.71171\n",
      "Epoch: 105, Loss: 0.29706, Train Acc: 0.90419, Test Acc: 0.74775\n",
      "Epoch: 106, Loss: 0.26070, Train Acc: 0.91417, Test Acc: 0.73874\n",
      "Epoch: 107, Loss: 0.28114, Train Acc: 0.89521, Test Acc: 0.70270\n",
      "Epoch: 108, Loss: 0.28057, Train Acc: 0.92515, Test Acc: 0.73874\n",
      "Epoch: 109, Loss: 0.25531, Train Acc: 0.90220, Test Acc: 0.72973\n",
      "Epoch: 110, Loss: 0.29501, Train Acc: 0.88124, Test Acc: 0.69369\n",
      "Epoch: 111, Loss: 0.29902, Train Acc: 0.89920, Test Acc: 0.72973\n",
      "Epoch: 112, Loss: 0.27130, Train Acc: 0.89920, Test Acc: 0.73874\n",
      "Epoch: 113, Loss: 0.26638, Train Acc: 0.91417, Test Acc: 0.72072\n",
      "Epoch: 114, Loss: 0.23287, Train Acc: 0.93812, Test Acc: 0.73874\n",
      "Epoch: 115, Loss: 0.21692, Train Acc: 0.93413, Test Acc: 0.73874\n",
      "Epoch: 116, Loss: 0.22772, Train Acc: 0.93912, Test Acc: 0.71171\n",
      "Epoch: 117, Loss: 0.21461, Train Acc: 0.91916, Test Acc: 0.61261\n",
      "Epoch: 118, Loss: 0.27199, Train Acc: 0.89122, Test Acc: 0.73874\n",
      "Epoch: 119, Loss: 0.25014, Train Acc: 0.92814, Test Acc: 0.70270\n",
      "Epoch: 120, Loss: 0.19871, Train Acc: 0.92914, Test Acc: 0.67568\n",
      "Epoch: 121, Loss: 0.21497, Train Acc: 0.93613, Test Acc: 0.70270\n",
      "Epoch: 122, Loss: 0.20377, Train Acc: 0.93214, Test Acc: 0.70270\n",
      "Epoch: 123, Loss: 0.20704, Train Acc: 0.92914, Test Acc: 0.72072\n",
      "Epoch: 124, Loss: 0.21974, Train Acc: 0.92814, Test Acc: 0.70270\n",
      "Epoch: 125, Loss: 0.21334, Train Acc: 0.94311, Test Acc: 0.71171\n",
      "Epoch: 126, Loss: 0.20189, Train Acc: 0.95110, Test Acc: 0.71171\n",
      "Epoch: 127, Loss: 0.17292, Train Acc: 0.95309, Test Acc: 0.73874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128, Loss: 0.17862, Train Acc: 0.95908, Test Acc: 0.69369\n",
      "Epoch: 129, Loss: 0.17694, Train Acc: 0.94810, Test Acc: 0.69369\n",
      "Epoch: 130, Loss: 0.15498, Train Acc: 0.93114, Test Acc: 0.72072\n",
      "Epoch: 131, Loss: 0.21982, Train Acc: 0.91218, Test Acc: 0.68468\n",
      "Epoch: 132, Loss: 0.21708, Train Acc: 0.94112, Test Acc: 0.66667\n",
      "Epoch: 133, Loss: 0.17883, Train Acc: 0.96108, Test Acc: 0.68468\n",
      "Epoch: 134, Loss: 0.18278, Train Acc: 0.94910, Test Acc: 0.65766\n",
      "Epoch: 135, Loss: 0.18160, Train Acc: 0.95709, Test Acc: 0.68468\n",
      "Epoch: 136, Loss: 0.19600, Train Acc: 0.94511, Test Acc: 0.69369\n",
      "Epoch: 137, Loss: 0.19639, Train Acc: 0.93713, Test Acc: 0.72072\n",
      "Epoch: 138, Loss: 0.18137, Train Acc: 0.95609, Test Acc: 0.70270\n",
      "Epoch: 139, Loss: 0.19140, Train Acc: 0.91317, Test Acc: 0.67568\n",
      "Epoch: 140, Loss: 0.24238, Train Acc: 0.93513, Test Acc: 0.71171\n",
      "Epoch: 141, Loss: 0.21919, Train Acc: 0.94112, Test Acc: 0.73874\n",
      "Epoch: 142, Loss: 0.16829, Train Acc: 0.96108, Test Acc: 0.70270\n",
      "Epoch: 143, Loss: 0.13392, Train Acc: 0.97705, Test Acc: 0.71171\n",
      "Epoch: 144, Loss: 0.13584, Train Acc: 0.96806, Test Acc: 0.69369\n",
      "Epoch: 145, Loss: 0.13476, Train Acc: 0.96806, Test Acc: 0.71171\n",
      "Epoch: 146, Loss: 0.15411, Train Acc: 0.92914, Test Acc: 0.71171\n",
      "Epoch: 147, Loss: 0.15226, Train Acc: 0.96407, Test Acc: 0.69369\n",
      "Epoch: 148, Loss: 0.12756, Train Acc: 0.96707, Test Acc: 0.70270\n",
      "Epoch: 149, Loss: 0.12544, Train Acc: 0.95709, Test Acc: 0.69369\n",
      "Epoch: 150, Loss: 0.17269, Train Acc: 0.96108, Test Acc: 0.65766\n",
      "Epoch: 151, Loss: 0.15791, Train Acc: 0.95609, Test Acc: 0.69369\n",
      "Epoch: 152, Loss: 0.16299, Train Acc: 0.97405, Test Acc: 0.68468\n",
      "Epoch: 153, Loss: 0.13619, Train Acc: 0.95808, Test Acc: 0.73874\n",
      "Epoch: 154, Loss: 0.20439, Train Acc: 0.92116, Test Acc: 0.74775\n",
      "Epoch: 155, Loss: 0.18376, Train Acc: 0.93713, Test Acc: 0.74775\n",
      "Epoch: 156, Loss: 0.17382, Train Acc: 0.95010, Test Acc: 0.73874\n",
      "Epoch: 157, Loss: 0.18711, Train Acc: 0.96507, Test Acc: 0.69369\n",
      "Epoch: 158, Loss: 0.18338, Train Acc: 0.94910, Test Acc: 0.71171\n",
      "Epoch: 159, Loss: 0.17346, Train Acc: 0.90319, Test Acc: 0.64865\n",
      "Epoch: 160, Loss: 0.29987, Train Acc: 0.91218, Test Acc: 0.71171\n",
      "Epoch: 161, Loss: 0.32360, Train Acc: 0.88024, Test Acc: 0.79279\n",
      "Epoch: 162, Loss: 0.31898, Train Acc: 0.90020, Test Acc: 0.73874\n",
      "Epoch: 163, Loss: 0.33071, Train Acc: 0.89122, Test Acc: 0.73874\n",
      "Epoch: 164, Loss: 0.28919, Train Acc: 0.89321, Test Acc: 0.76577\n",
      "Epoch: 165, Loss: 0.27016, Train Acc: 0.90719, Test Acc: 0.74775\n",
      "Epoch: 166, Loss: 0.25318, Train Acc: 0.91816, Test Acc: 0.75676\n",
      "Epoch: 167, Loss: 0.23475, Train Acc: 0.92116, Test Acc: 0.77477\n",
      "Epoch: 168, Loss: 0.22668, Train Acc: 0.92814, Test Acc: 0.73874\n",
      "Epoch: 169, Loss: 0.23254, Train Acc: 0.93313, Test Acc: 0.74775\n",
      "Epoch: 170, Loss: 0.21523, Train Acc: 0.94411, Test Acc: 0.74775\n",
      "Epoch: 171, Loss: 0.21016, Train Acc: 0.92216, Test Acc: 0.75676\n",
      "Epoch: 172, Loss: 0.21194, Train Acc: 0.93014, Test Acc: 0.72973\n",
      "Epoch: 173, Loss: 0.19371, Train Acc: 0.94511, Test Acc: 0.75676\n",
      "Epoch: 174, Loss: 0.20651, Train Acc: 0.94810, Test Acc: 0.72973\n",
      "Epoch: 175, Loss: 0.19754, Train Acc: 0.94611, Test Acc: 0.75676\n",
      "Epoch: 176, Loss: 0.19437, Train Acc: 0.95709, Test Acc: 0.76577\n",
      "Epoch: 177, Loss: 0.16198, Train Acc: 0.95609, Test Acc: 0.76577\n",
      "Epoch: 178, Loss: 0.20577, Train Acc: 0.94012, Test Acc: 0.76577\n",
      "Epoch: 179, Loss: 0.19140, Train Acc: 0.93713, Test Acc: 0.76577\n",
      "Epoch: 180, Loss: 0.21780, Train Acc: 0.90020, Test Acc: 0.74775\n",
      "Epoch: 181, Loss: 0.27181, Train Acc: 0.92315, Test Acc: 0.71171\n",
      "Epoch: 182, Loss: 0.19951, Train Acc: 0.93812, Test Acc: 0.72072\n",
      "Epoch: 183, Loss: 0.18322, Train Acc: 0.95908, Test Acc: 0.76577\n",
      "Epoch: 184, Loss: 0.16047, Train Acc: 0.97206, Test Acc: 0.72973\n",
      "Epoch: 185, Loss: 0.14935, Train Acc: 0.95010, Test Acc: 0.73874\n",
      "Epoch: 186, Loss: 0.18384, Train Acc: 0.94212, Test Acc: 0.73874\n",
      "Epoch: 187, Loss: 0.20257, Train Acc: 0.95709, Test Acc: 0.78378\n",
      "Epoch: 188, Loss: 0.18100, Train Acc: 0.90818, Test Acc: 0.69369\n",
      "Epoch: 189, Loss: 0.18155, Train Acc: 0.94212, Test Acc: 0.75676\n",
      "Epoch: 190, Loss: 0.13615, Train Acc: 0.97106, Test Acc: 0.73874\n",
      "Epoch: 191, Loss: 0.10745, Train Acc: 0.96607, Test Acc: 0.70270\n",
      "Epoch: 192, Loss: 0.12132, Train Acc: 0.97605, Test Acc: 0.77477\n",
      "Epoch: 193, Loss: 0.14102, Train Acc: 0.96307, Test Acc: 0.71171\n",
      "Epoch: 194, Loss: 0.15598, Train Acc: 0.95110, Test Acc: 0.71171\n",
      "Epoch: 195, Loss: 0.20305, Train Acc: 0.93214, Test Acc: 0.73874\n",
      "Epoch: 196, Loss: 0.20375, Train Acc: 0.95110, Test Acc: 0.81081\n",
      "Epoch: 197, Loss: 0.17210, Train Acc: 0.96307, Test Acc: 0.77477\n",
      "Epoch: 198, Loss: 0.14380, Train Acc: 0.95709, Test Acc: 0.79279\n",
      "Epoch: 199, Loss: 0.15327, Train Acc: 0.97804, Test Acc: 0.73874\n",
      "Epoch: 200, Loss: 0.13478, Train Acc: 0.97405, Test Acc: 0.74775\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data).max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train(epoch)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print('Epoch: {:03d}, Loss: {:.5f}, Train Acc: {:.5f}, Test Acc: {:.5f}'.\n",
    "          format(epoch, loss, train_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Edge Conv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric import datasets\n",
    "dataset = datasets.TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) #dataset include 600 graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37, 23, 25, 24, 23, 24, 26, 88, 23, 32, 4, 14, 42, 41, 36, 55, 40, 38, 2, 35, 42, 41, 39, 42, 41, 40, 37, 23, 22, 34, 38, 38, 39, 8, 23, 42, 42, 100, 24, 24, 47, 45, 45, 45, 46, 44, 30, 32, 33, 9, 27, 39, 16, 18, 7, 18, 10, 21, 18, 10, 9, 39, 33, 29, 24, 25, 30, 38, 28, 28, 38, 40, 40, 42, 20, 19, 16, 17, 20, 18, 33, 23, 23, 35, 33, 39, 40, 38, 40, 38, 37, 36, 34, 34, 32, 18, 32, 34, 30, 5, 45, 42, 59, 32, 33, 17, 39, 38, 35, 16, 26, 51, 52, 25, 27, 42, 46, 96, 12, 22, 42, 14, 90, 14, 14, 32, 11, 26, 11, 14, 18, 16, 17, 32, 13, 3, 22, 16, 38, 13, 12, 14, 39, 19, 20, 39, 40, 39, 39, 29, 22, 11, 8, 13, 18, 12, 8, 40, 12, 22, 22, 18, 12, 17, 14, 22, 43, 42, 44, 24, 48, 25, 46, 48, 25, 48, 44, 42, 40, 38, 40, 41, 42, 40, 44, 24, 44, 20, 42, 27, 48, 31, 30, 46, 47, 50, 40, 55, 62, 34, 29, 25, 56, 57, 27, 22, 24, 23, 57, 24, 24, 23, 25, 23, 48, 27, 15, 44, 29, 21, 34, 30, 40, 54, 18, 36, 37, 34, 23, 32, 33, 29, 39, 34, 36, 21, 6, 22, 18, 18, 34, 32, 33, 28, 40, 42, 39, 28, 29, 30, 14, 32, 35, 24, 17, 18, 16, 19, 19, 21, 23, 25, 27, 24, 24, 32, 31, 33, 34, 32, 32, 44, 40, 40, 38, 30, 38, 44, 60, 28, 16, 50, 52, 48, 50, 42, 43, 41, 39, 38, 62, 60, 96, 54, 124, 126, 122, 24, 41, 49, 44, 42, 41, 42, 46, 55, 50, 42, 48, 51, 24, 51, 52, 22, 44, 44, 31, 27, 25, 38, 21, 29, 20, 21, 50, 46, 49, 27, 12, 14, 23, 24, 33, 27, 25, 28, 28, 12, 26, 28, 28, 26, 24, 23, 27, 39, 42, 42, 64, 38, 22, 9, 26, 19, 66, 27, 34, 28, 26, 26, 28, 19, 20, 20, 42, 42, 15, 11, 10, 12, 30, 15, 10, 18, 22, 12, 36, 30, 30, 36, 33, 48, 27, 27, 16, 7, 16, 35, 28, 40, 26, 48, 15, 11, 50, 18, 19, 14, 21, 37, 48, 25, 28, 33, 29, 33, 30, 33, 32, 28, 37, 36, 38, 37, 34, 24, 25, 41, 27, 26, 25, 27, 20, 40, 21, 19, 36, 32, 28, 37, 18, 19, 22, 43, 24, 15, 14, 48, 46, 26, 25, 44, 39, 39, 27, 26, 25, 39, 26, 26, 26, 34, 20, 20, 19, 18, 33, 15, 34, 28, 34, 15, 14, 20, 52, 20, 20, 20, 17, 12, 24, 46, 13, 24, 12, 12, 14, 20, 28, 24, 12, 26, 22, 60, 39, 26, 15, 25, 35, 35, 38, 38, 33, 32, 42, 42, 41, 40, 38, 43, 67, 36, 46, 66, 21, 22, 21, 21, 41, 29, 30, 30, 41, 37, 26, 37, 50, 27, 34, 32, 35, 37, 48, 41, 29, 58, 57, 21, 18, 42, 40, 74, 44, 44, 40, 44, 42, 43, 41, 49, 84, 44, 42, 41, 41, 44, 39, 25, 25, 26, 52, 41, 45, 31, 26, 26, 52, 50, 38, 37, 27, 29, 48, 40, 19, 14, 13, 13, 44, 45, 46, 47, 47, 42, 51, 27, 27, 60, 28, 38, 23, 18, 45, 21, 35, 24, 21, 21, 31, 27, 51, 36, 46, 52, 44, 45, 52, 55, 51, 48]\n"
     ]
    }
   ],
   "source": [
    "#check the number of nodes of each graph\n",
    "print([len(g.x) for g in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train/test\n",
    "\n",
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:540]\n",
    "test_dataset = dataset[540:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini-batches\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Edge Conv model\n",
    "\n",
    "DGCNN\n",
    "\n",
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential as Seq, Dropout, Linear as Lin, ReLU, BatchNorm1d as BN\n",
    "from torch_geometric.nn import DynamicEdgeConv, global_max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Lin(channels[i - 1], channels[i]), ReLU(), BN(channels[i]))\n",
    "        for i in range(1, len(channels))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, out_channels, k=20, aggr='max'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = DynamicEdgeConv(MLP([2 * 3, 64, 64, 64]), k, aggr)\n",
    "        self.conv2 = DynamicEdgeConv(MLP([2 * 64, 128]), k, aggr)\n",
    "        self.lin1 = MLP([128 + 64, 1024])\n",
    "\n",
    "        self.mlp = Seq(\n",
    "            MLP([1024, 512]), Dropout(0.5), MLP([512, 256]), Dropout(0.5),\n",
    "            Lin(256, out_channels))\n",
    "\n",
    "    def forward(self, data):\n",
    "        pos, batch = data.pos, data.batch\n",
    "        x1 = self.conv1(pos, batch)\n",
    "        x2 = self.conv2(x1, batch)\n",
    "        out = self.lin1(torch.cat([x1, x2], dim=1))\n",
    "        out = global_max_pool(out, batch)\n",
    "        out = self.mlp(out)\n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a985e69d0902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     print('Epoch {:03d}, Loss: {:.4f}, Test: {:.4f}'.format(\n",
      "\u001b[0;32m<ipython-input-12-a985e69d0902>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-dca6be8b4e4a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch_geometric/nn/conv/edge_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, batch)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDynamicEdgeConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch_cluster/knn.py\u001b[0m in \u001b[0;36mknn_graph\u001b[0;34m(x, k, batch, loop, flow, cosine)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'source_to_target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target_to_source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mloop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'source_to_target'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch_cluster/knn.py\u001b[0m in \u001b[0;36mknn\u001b[0;34m(x, y, k, batch_x, batch_y, cosine)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \"\"\"\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_classes, k=20).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return total_loss / len(train_dataset)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            pred = model(data).max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    test_acc = test(test_loader)\n",
    "    print('Epoch {:03d}, Loss: {:.4f}, Test: {:.4f}'.format(\n",
    "        epoch, loss, test_acc))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More examples\n",
    "\n",
    "https://github.com/rusty1s/pytorch_geometric/tree/master/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
